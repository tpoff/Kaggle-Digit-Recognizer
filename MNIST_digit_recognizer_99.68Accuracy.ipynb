{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7756d671-a890-4558-be42-0c0aed6b15a4",
   "metadata": {},
   "source": [
    "# Creating a Digit Recognizer Model with the Kaggle MNIST Dataset\n",
    "## A Newbies First Attempt at a High Performance Deep learning with Model Ensembling, Achieved 99.68% accuracy\n",
    "Reader beware, newbie at work.\n",
    "\n",
    "Over the past few years I have played with the idea of truly mastering Deep Learning. Last year I actually studied up and managed to earn the Tensorflow Certification for Deep Learning. An achievement I'm still proud of, but must admit was much easier than I was expecting. I walked away thinking that it was more of an very basic introduction than a high ranking goal for truly learning this field. So this year I decided to really do my best to learn everything I can about creating Deep Learning models myself and with the intention of making as good of a model as I can. To that end I decided to start at the very beginning with the MNIST dataset, and to make it extra interesting I decided to use this opportunity to learn another deep learning framework besides Tensorflow, PyTorch. \n",
    "\n",
    "In this notebook I go over my initial data analysis, model architecture, training strategy and ensembling approach to build the highest performing model that I can on the Kaggle version of the MNIST dataset. With a focus on maintaining reproducability for the experiments. The final model will be an ensemble model of the top 10 performing models. For this notebook we will train 30 models in total each with 40 epochs. We will use data augmentation to produce new images from our training dataset to help generalize the model to the best of our ability. \n",
    "\n",
    "In the end I was able to develop a rough model pipeline that can produce a model that achieved 99.685% accuracy on the hidden dataset in Kaggle, with additional manual testing I found a subset of all trained models that achieve an accuracy of 99.7% through trial and error. \n",
    "\n",
    "I will also summarize some of the lessons I've learned and what I will take into account for future projects. \n",
    "\n",
    "<b>A NOTE ON REPRODUCABILITY:</b> One of the major take aways I got from this project was the need to be able to reproduce the results of an experiment, so long as nothing has changed it's important to be able to hit run and get the same scores and metrics and previous runs. This is vital for ensuring that a change made to the code actually benefits or hurts the end result, otherwise it's possible that a change you made was actually hurtful overall, but because of a lucky split of the data the metrics turned out positive. That being said, I was not able to fully replicate the results of this notebook on Kaggle. After experimenting with the various offerings on kaggle for gpu acceleration I believe the issue has to do with the GPUs themselves. My own GPU on my local machine is an Nvidia 3090 with cuda 11.6, the offerings on Kaggle are a duel T4 gpu setup with Cuda 11.3, and a P100 gpu again with Cuda 11.3. Each of these gpus running the same notebook produced different end results. Those end results were always the same, so everytime you ran the notebook on the P100 you would get the same result, but that result would differ from runs on the T4 gpus and my 3090. This is really confusing considering that the Cuda version for the Kaggle offerings are the same, so this makes me wonder if perhaps there is some architecture differences in play, but this is pure speculation. All that to say, if you run this notebook on a kaggle kernel the results will vary. I have saved the models from my local training to github if you want to use them. I'm really sorry, I tried my best to figure it out but was unable to, I still would like to share the notebook as at least a record of my attempt. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca07b27c-2beb-4fbf-8a4a-fe7aba4d301f",
   "metadata": {},
   "source": [
    "## Importing libraries and defining some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3660dc8-ce36-4b79-9841-6674b8ebd1c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T07:13:56.987450Z",
     "iopub.status.busy": "2023-03-28T07:13:56.987450Z",
     "iopub.status.idle": "2023-03-28T07:14:00.788449Z",
     "shell.execute_reply": "2023-03-28T07:14:00.788052Z",
     "shell.execute_reply.started": "2023-03-28T07:13:56.987450Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tyler\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import RandomRotation, RandomHorizontalFlip, RandomPerspective, RandomAffine, Lambda, Normalize, ColorJitter, ToPILImage\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import os\n",
    "import math\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a5de697-bf0e-4012-bb8a-4649a4c850a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T07:14:00.789448Z",
     "iopub.status.busy": "2023-03-28T07:14:00.789448Z",
     "iopub.status.idle": "2023-03-28T07:14:00.803951Z",
     "shell.execute_reply": "2023-03-28T07:14:00.803554Z",
     "shell.execute_reply.started": "2023-03-28T07:14:00.789448Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version:  1.13.0+cu116\n",
      "Numpy version:  1.24.2\n",
      "Pandas version:  1.4.2\n",
      "torchvision version:  0.14.0+cu116\n",
      "sklearn version:  1.0.2\n",
      "cuda version:  11.6\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch version: \", torch.__version__)\n",
    "print(\"Numpy version: \", np.__version__)\n",
    "print(\"Pandas version: \", pd.__version__)\n",
    "print(\"torchvision version: \", torchvision.__version__)\n",
    "print(\"sklearn version: \", sklearn.__version__)\n",
    "print(\"cuda version: \", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fe3b8d9-691e-4f27-8271-e1b23334b310",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T07:14:00.805949Z",
     "iopub.status.busy": "2023-03-28T07:14:00.805482Z",
     "iopub.status.idle": "2023-03-28T07:14:00.819950Z",
     "shell.execute_reply": "2023-03-28T07:14:00.818951Z",
     "shell.execute_reply.started": "2023-03-28T07:14:00.805949Z"
    }
   },
   "outputs": [],
   "source": [
    "# this might be needed depending on your cuda version and gpu. Some of the newer version of cuda have non-deterministic actions for certain events which plays havoc on reproducability, \n",
    "# this forces cuda to use a deterministic version of actions when available. \n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461798cb-1f40-49d2-af48-20f6e4946baa",
   "metadata": {},
   "source": [
    "Check what type of compute environment we have, if we have a gpu we can utilize. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e5699b5-807c-4bb4-91f8-1c67513a7b2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T07:14:00.820448Z",
     "iopub.status.busy": "2023-03-28T07:14:00.820448Z",
     "iopub.status.idle": "2023-03-28T07:14:00.881365Z",
     "shell.execute_reply": "2023-03-28T07:14:00.880462Z",
     "shell.execute_reply.started": "2023-03-28T07:14:00.820448Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available devices: 2\n",
      "current device: 0\n"
     ]
    }
   ],
   "source": [
    "print(f'available devices: {torch.cuda.device_count()}')\n",
    "print(f'current device: { torch.cuda.current_device()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81f9ac1b-03e9-47b2-8162-927d283081d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T07:14:00.882365Z",
     "iopub.status.busy": "2023-03-28T07:14:00.882365Z",
     "iopub.status.idle": "2023-03-28T07:14:00.896599Z",
     "shell.execute_reply": "2023-03-28T07:14:00.895597Z",
     "shell.execute_reply.started": "2023-03-28T07:14:00.882365Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a093e11-c304-4091-a54f-55976f4fc069",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T07:14:00.897600Z",
     "iopub.status.busy": "2023-03-28T07:14:00.897099Z",
     "iopub.status.idle": "2023-03-28T07:14:00.911598Z",
     "shell.execute_reply": "2023-03-28T07:14:00.911096Z",
     "shell.execute_reply.started": "2023-03-28T07:14:00.897600Z"
    }
   },
   "outputs": [],
   "source": [
    "random_seed = 31262 # define a random seed to ensure reproducability of results\n",
    "num_models_to_train = 30 # since our end goal will be an ensemble of our top models, we will define how many models we want to train overall here\n",
    "num_epochs = 40 # likewise how long to train each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b49fa329-8bfe-4768-9cd2-f6e1a8ab86a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T07:14:00.912598Z",
     "iopub.status.busy": "2023-03-28T07:14:00.912598Z",
     "iopub.status.idle": "2023-03-28T07:14:00.927491Z",
     "shell.execute_reply": "2023-03-28T07:14:00.926491Z",
     "shell.execute_reply.started": "2023-03-28T07:14:00.912598Z"
    }
   },
   "outputs": [],
   "source": [
    "input_folder_path = \"../input/\" # where's all the data?\n",
    "checkpoint_location = \"./model_checkpoints/\" # intermediate folder where we will store our model checkpoints\n",
    "scores_json_location = \"./model_data.json\" # also define a location to store a json file with our model data, such as final accuracy score and file location. \n",
    "\n",
    "# verify our model checkpoint directory exists.\n",
    "if not os.path.exists(checkpoint_location):\n",
    "    os.makedirs(checkpoint_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87251ec9-010b-4d3b-a325-40be9cdafa5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T07:14:00.928491Z",
     "iopub.status.busy": "2023-03-28T07:14:00.927994Z",
     "iopub.status.idle": "2023-03-28T07:14:00.942313Z",
     "shell.execute_reply": "2023-03-28T07:14:00.941805Z",
     "shell.execute_reply.started": "2023-03-28T07:14:00.927994Z"
    }
   },
   "outputs": [],
   "source": [
    "num_models_to_ensemble = 10 # how many of the top models do we want to include in our ensemble model. \n",
    "\n",
    "batch_size = 1024 # batch size used for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5540d6-a7ef-44ef-8ad3-d7b926e6a789",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "so first thing's first, let's load in our data and do some light analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62e10268-fb9c-4de9-a4e6-768a88f52753",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T07:14:00.943312Z",
     "iopub.status.busy": "2023-03-28T07:14:00.943312Z",
     "iopub.status.idle": "2023-03-28T07:14:02.724311Z",
     "shell.execute_reply": "2023-03-28T07:14:02.723812Z",
     "shell.execute_reply.started": "2023-03-28T07:14:00.943312Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load our training data\n",
    "train_df = pd.read_csv(input_folder_path+\"train.csv\")\n",
    "train_labels = train_df['label'].values\n",
    "train_features = (train_df.iloc[:,1:].values).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "034f9388-3413-42d4-8efb-7357ef0f84ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T07:14:02.725812Z",
     "iopub.status.busy": "2023-03-28T07:14:02.725312Z",
     "iopub.status.idle": "2023-03-28T07:14:02.740336Z",
     "shell.execute_reply": "2023-03-28T07:14:02.739312Z",
     "shell.execute_reply.started": "2023-03-28T07:14:02.725312Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20614c4-675c-4d17-af39-8c7f21071dc0",
   "metadata": {},
   "source": [
    "### Visualize  some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6916bbb9-9972-4b62-a3fd-c7dfb597e0a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T07:14:02.741329Z",
     "iopub.status.busy": "2023-03-28T07:14:02.740811Z",
     "iopub.status.idle": "2023-03-28T07:14:03.375312Z",
     "shell.execute_reply": "2023-03-28T07:14:03.374815Z",
     "shell.execute_reply.started": "2023-03-28T07:14:02.741329Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape:  (28, 28)\n",
      "image min/max: (0.0, 255.0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns = 3\n",
    "rows = 3\n",
    "fig = plt.figure()\n",
    "print(\"image shape: \", train_features[0].reshape((28, 28)).shape)\n",
    "print(\"image min/max: (%s, %s)\"%(train_features[0].min(), train_features[0].max()))\n",
    "for i in range(columns*rows):\n",
    "    image = train_features[i].reshape((28, 28))\n",
    "    plt.subplot(columns, rows, i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(image, cmap=\"gray\", interpolation=\"none\")\n",
    "    plt.title(\"Label:\"+str(train_labels[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0cdff4-4b3b-44c8-9321-9dbc4b6fc903",
   "metadata": {},
   "source": [
    "So each image is 28x28 pixels and single channel, so no color information we need to be concered about. We can also see that the values for the image range from 0 to 255. We will need to normalize these into a 0 to 1 range later. Luckily Pytorch will make this easy for us \n",
    "\n",
    "Just looking at the samples here we can already see some variation with samples with the same label, that first '1' is very lopsided and some '0's look like they're drawn more thickly than others, and some are more round or oval. We'll need a pretty robust network to help generalize to these differences. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c75798-1737-4fb3-89d7-4d1e635fb482",
   "metadata": {},
   "source": [
    "### Class Distribution\n",
    "Let's ensure that we don't have any balance issues with our classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b48f97d8-304c-4948-a371-2729b9d7cb18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T07:14:03.378811Z",
     "iopub.status.busy": "2023-03-28T07:14:03.378312Z",
     "iopub.status.idle": "2023-03-28T07:14:03.607812Z",
     "shell.execute_reply": "2023-03-28T07:14:03.607310Z",
     "shell.execute_reply.started": "2023-03-28T07:14:03.378811Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 4684, 7: 4401, 3: 4351, 9: 4188, 2: 4177, 6: 4137, 0: 4132, 4: 4072, 8: 4063, 5: 3795})\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counter = Counter(train_labels)\n",
    "print(counter)\n",
    "fig, ax = plt.subplots()\n",
    "bars = ax.bar(counter.keys(), counter.values(), tick_label=list(counter.keys()))\n",
    "ax.tick_params(bottom=False, left=False)\n",
    "ax.set_axisbelow(True)\n",
    "ax.yaxis.grid(True, color='#EEEEEE')\n",
    "ax.xaxis.grid(False)\n",
    "ax.set_xlabel(\"Label\")\n",
    "ax.set_ylabel(\"Label Count in Dataset\")\n",
    "ax.set_title(\"Distribution of labels\",  pad=15, color=\"#333333\", weight=\"bold\")\n",
    "\n",
    "for bar in bars:\n",
    "    ax.text(\n",
    "      bar.get_x() + bar.get_width() / 2,\n",
    "      bar.get_height() + bar.get_height()*.03,\n",
    "      round(bar.get_height()+ 5, 1),\n",
    "      horizontalalignment='center'\n",
    "    )\n",
    "\n",
    "    \n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395c5ba5-2749-46b9-96c2-c277600b23b7",
   "metadata": {},
   "source": [
    "So the classes aren't totally even, class '1' has the most samples, and '5' has the fewest. We might want to keep this in mind in case we run into issues training the model later, as it might over predict for 1 and underpredict for 5. For this beginner dataset I don't think this will be much of an issue, but always useful to check and keep in mind. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5387b140-de7b-445d-ba0d-fa6dcb95087f",
   "metadata": {},
   "source": [
    "## Data Preperation \n",
    "The only data cleaning we will need to do is to normalize the image values to a range between 0 and 1, we want the inputs to be small so that it's easier for our network to learn off of them and to prevent the weights from exploding (getting too large of values as to near infinity). Luckily when we convert our data to a tensor using ToTensor from a PIL image the function automatically does that for us. So all we need to do is create a transform to convert to a PIL image then a tensor. Easy. \n",
    "\n",
    "The other aspect we will want to prep for is data augmentation. This is where we will take our training data and slightly tweak the image to produce another sample. This can be things like rotating the image slightly, scaling up or down, shifting the image left or right, or adjust the color so it's slightly different. All of these will produce slight variations to our data that our model can use to better generalize to the concept behind a number 3 rather than just trying to memorize the training data itself. We will apply these transforms randomly, so everytime we go to get more data it will always be slightly different. Note: When using actions that require randomness or aren't deterministic be sure to keep reproducability in mind, later in this notebook we set our random seeds, so everytime we rely on randomness we will generate the same set of random numbers, so everytime we run this notebook we get the same results, but without this then our results can vary wildly between each run. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12159399-186e-47d2-a67f-777064e212dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T07:14:03.609311Z",
     "iopub.status.busy": "2023-03-28T07:14:03.608811Z",
     "iopub.status.idle": "2023-03-28T07:14:03.623310Z",
     "shell.execute_reply": "2023-03-28T07:14:03.622810Z",
     "shell.execute_reply.started": "2023-03-28T07:14:03.609311Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a transform pipeline to convert to an image, apply random rotation, translation, scale and color jitter. Also convert to a tensor to be fed into our model. \n",
    "train_transform = transforms.Compose([\n",
    "    ToPILImage(),\n",
    "    RandomRotation(degrees=(-15, 15)),\n",
    "    RandomAffine(degrees=5, translate=(0.15,0.15), scale=(0.75, 1.15)),\n",
    "    ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c52795-6450-4747-850e-569ee68f33d2",
   "metadata": {},
   "source": [
    "We'll also need to create a custom torch dataset class, this will help us control how we fetch and generate samples to train our model on. With this class we can just pass in our images and labels and our transform pipeline and we can write code to format\n",
    "the images as needed and apply the transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d36ef47-07fb-45dd-9298-30a174dc34a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T07:14:03.624812Z",
     "iopub.status.busy": "2023-03-28T07:14:03.624312Z",
     "iopub.status.idle": "2023-03-28T07:14:03.639311Z",
     "shell.execute_reply": "2023-03-28T07:14:03.638310Z",
     "shell.execute_reply.started": "2023-03-28T07:14:03.624812Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomTensorDataset(torch.utils.data.Dataset):\n",
    "    # images df, labels df, transforms\n",
    "    # uses labels to determine if it needs to return X & y or just X in __getitem__\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.X = images\n",
    "        self.y = labels\n",
    "        self.transforms = transform\n",
    "                    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        data = self.X[i] # gets the row\n",
    "        # reshape the row into the image size \n",
    "        data = np.array(data).astype(np.uint8).reshape(28, 28) \n",
    "        \n",
    "        # perform transforms if there are any\n",
    "        if self.transforms:\n",
    "            data = self.transforms(data)\n",
    "            \n",
    "        \n",
    "        # if !test_set return the label as well, otherwise don't\n",
    "        if self.y is not None: # train/val\n",
    "            return (data, self.y[i])\n",
    "        else: # test\n",
    "            return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4febfc3a-71f1-4452-a7c7-6709f4bc1e24",
   "metadata": {},
   "source": [
    "Finally create some helper functions that can take in a set of features, labels, transformer pipeline and generator (to help control the randomness for reproducability) and return a DataLoader. \n",
    "\n",
    "Pytorch's dataloaders help batch our data to help with memory constraints or to just help with organization, they're a useful tool in the pytorch utilities!\n",
    "\n",
    "We also create a helper function that can take in a compelete dataset and split it into a train and test dataset. For each model we will use a different cut of the data for training and testing, so each model will be trained on slightly different data. There is an argument to be made that the same test and train data should be used for each model we train, but so long as our final validation dataset remains static I think it's fine to use a different train/test set for each model we will experiment with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f95789da-92cf-47d1-8902-660ced53d463",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T07:14:03.640811Z",
     "iopub.status.busy": "2023-03-28T07:14:03.640311Z",
     "iopub.status.idle": "2023-03-28T07:14:03.654811Z",
     "shell.execute_reply": "2023-03-28T07:14:03.653810Z",
     "shell.execute_reply.started": "2023-03-28T07:14:03.640811Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_dataloader(features, labels, transformer, generator):\n",
    "    train_images_tensor = torch.tensor(features)\n",
    "    train_labels_tensor = torch.tensor(labels)\n",
    "    train_tensor = CustomTensorDataset(train_images_tensor, train_labels_tensor, transform=transformer)    \n",
    "    train_dataloader = DataLoader(train_tensor, batch_size=batch_size, shuffle=True, generator=generator)\n",
    "    return train_dataloader\n",
    "    \n",
    "        \n",
    "def create_train_val_dataloaders(features, labels, train_transformer=None, test_transformer=None, test_size=.2):\n",
    "    train_images, val_images, train_labels, val_labels = train_test_split(features, labels,\n",
    "                                                                     stratify=labels,\n",
    "                                                                     test_size=test_size)\n",
    "   \n",
    "    if test_transformer == None:\n",
    "        test_transformer = ToTensor()\n",
    "    if train_transformer == None:\n",
    "        train_transformer = ToTensor()\n",
    "    train_dataloader = create_dataloader(train_images, train_labels, train_transformer, g)\n",
    "    \n",
    "    val_dataloader = create_dataloader(val_images, val_labels, test_transformer, g)\n",
    "    return train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85225ca-4eba-43af-9767-d6ed231a8134",
   "metadata": {},
   "source": [
    "Finally we will create a torch generator which will help us with reproducability, we'll feed it the same seed every time and it will produce the same set of \"random\" numbers. This way we can validate if a certain approach or modification to our training routine works or if it was just a really lucky training iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "872927dd-f9af-49b9-b1fe-485c4b8245d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T07:14:03.656313Z",
     "iopub.status.busy": "2023-03-28T07:14:03.655812Z",
     "iopub.status.idle": "2023-03-28T07:14:03.669810Z",
     "shell.execute_reply": "2023-03-28T07:14:03.669311Z",
     "shell.execute_reply.started": "2023-03-28T07:14:03.656313Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x239b0d20d70>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.Generator()\n",
    "g.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfd50ac-df0c-4b0d-a901-034d13b345d5",
   "metadata": {},
   "source": [
    "## Defining our model\n",
    "So full disclosure, this model architecture is probably way bigger than it needs to be, however this was an intentional choice to make it larger. While this does increase the risk of overfitting and take longer to converge, the end goal of this notebook is to create an ensemble model, so we want our smaller models to be more diverse to make up for each others weaknesses, where 1 model fails to predict correctly we want 2-3 other models to make up for that mistake. To that end we want a model architecture that allows for models to learn in different ways, a larger model means there are more parameters and more local minima that it can settle into, meaning the final model has a better opportunity to be different than a previously trained model. With smaller models there is a risk that they all essentially backpropogate to the same configuration. \n",
    "\n",
    "So larger model it is, and we'll just be sure to keep an eye not to overfit during training. \n",
    "\n",
    "The model itself uses 6 convolutional network layers, with Max Pooling and batch normalization between each layer with a LeakyReLU activation function. We then flatten the inputs and pass them through a 512 node linear layer, again with batch norm and LeakyReLU before passing to our output layer for our 10 classes. We wrap it up by using a log_softmax function to produce probabilities for each class.\n",
    "\n",
    "We also include a dropout layer for each individual layer configured to 10% probability, to help with generalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23227810-a5e6-4a9e-a6e8-e32058a6106b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T07:14:03.671311Z",
     "iopub.status.busy": "2023-03-28T07:14:03.670810Z",
     "iopub.status.idle": "2023-03-28T07:14:03.685811Z",
     "shell.execute_reply": "2023-03-28T07:14:03.684812Z",
     "shell.execute_reply.started": "2023-03-28T07:14:03.671311Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, dropout_rate=.1):\n",
    "        super(Model, self).__init__()          \n",
    "        self.sequential_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, bias=False, padding=1), \n",
    "            nn.MaxPool2d(kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "             nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            \n",
    "            nn.Conv2d(64, 64, 3, bias=False), \n",
    "            nn.MaxPool2d(kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "             nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            \n",
    "            nn.Conv2d(64, 64, 3, bias=False, padding=1), \n",
    "            nn.MaxPool2d(kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "             nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 3, bias=False, padding=1), \n",
    "            nn.MaxPool2d(kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "             nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout_rate),   \n",
    "            \n",
    "            nn.Conv2d(128, 128, 3, bias=False, padding=1), \n",
    "            nn.MaxPool2d(kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "             nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout_rate), \n",
    "            \n",
    "            nn.Conv2d(128, 128, 3, bias=False, padding=1), \n",
    "            nn.MaxPool2d(kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "             nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout_rate),                                \n",
    "            \n",
    "            nn.Flatten(1, -1),\n",
    "            \n",
    "            nn.LazyLinear(512, bias=False),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            \n",
    "            nn.LazyLinear(10, bias=False),\n",
    "            nn.BatchNorm1d(10)\n",
    "            \n",
    "        )\n",
    "    def get_logits(self, x):\n",
    "        return self.sequential_layers(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        logits = self.get_logits(x)\n",
    "        return F.log_softmax(logits, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2854618-7ce2-4c6d-a761-115c37da6b06",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "So now we have a model architecture defined, time to start training. \n",
    "\n",
    "For each model we will use an Adam Optimizer with a learning rate of 0.001 and a weight decay of 1e-5. The weight decay applies a L2 regularization on the model, meaning that it helps prevent overfitting and exploding weights, so it helps control the learning of the model basically. \n",
    "We also define a learning rate decay of .98 for each epoch, meaning the learning rate will decrease by .98 every time we start a new training epoch, this lets our model converge to a better score, without it the backpropogation might have the model cycle never reaching a good local minima, this way we get a bit closer to that goal. Our loss function is going to be cross entropy which is a good loss function for this type of problem. \n",
    "\n",
    "We will train n models (in this case n=30), and we'll score each model based on how well it does on the entire training dataset (not just its specific validation set), the top 10 models will then be selected to form an ensemble model to make our final predictions. We only use the top 10 because if we include too many models we just add to much noise to the final predictions, around 7-11 models seems to be the ideal sweet spot from my experimentation. 10 is a good even number so that's what we choose. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89c12c3-9256-4f74-9024-fac32828acf0",
   "metadata": {},
   "source": [
    "### Training Helper Functions\n",
    "Since we'll be training several nets it'll be helpful to go ahead and define a few functions we can reuse. This is by no means the best pipeline for training, in fact looking at the number of parameters in the train_model function it probably could have benefited from some refactoring and cleanup, maybe even just turn it into a class, but I digress. \n",
    "\n",
    "Everything is pretty standard, we will save the best weights from the model after every epoch as based on the accuracy of the test data, and at the end of the training cycle we will reload the best weights and return that model as the final model. There's room for improvement but it does it's job. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a29bf705-beac-45dd-8c4b-1d39fda6a9e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T07:14:03.688312Z",
     "iopub.status.busy": "2023-03-28T07:14:03.687811Z",
     "iopub.status.idle": "2023-03-28T07:14:03.716812Z",
     "shell.execute_reply": "2023-03-28T07:14:03.715811Z",
     "shell.execute_reply.started": "2023-03-28T07:14:03.688312Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_step(model, loss_fn, accuracy_fn, optimizer, train_dataloader, device, eval_loss_fn=None):    \n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    for batch_index, (data, target) in enumerate(train_dataloader):\n",
    "        data = data.unsqueeze(1)\n",
    "        data = data.squeeze(1)\n",
    "        data, target = data.to(device), target.to(device, dtype=torch.int64)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_accuracy += accuracy_fn(output, target).item()\n",
    "        if eval_loss_fn==None:\n",
    "            train_loss += loss.item()\n",
    "        else:\n",
    "            train_loss += eval_loss_fn(output, target).item()\n",
    "        del data\n",
    "        del target\n",
    "    train_loss /= len(train_dataloader.dataset)\n",
    "    train_accuracy /= len(train_dataloader.dataset)\n",
    "    return train_loss, train_accuracy\n",
    "        \n",
    "def test_step(model, loss_fn, accuracy_fn, test_dataloader, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_accuracy = 0\n",
    "    total_pred = np.zeros(0)\n",
    "    total_target = np.zeros(0)\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_dataloader:\n",
    "            data, target = data.to(device), target.to(device, dtype=torch.int64)\n",
    "            output = model(data)          \n",
    "            \n",
    "            test_loss += loss_fn(output, target).item()\n",
    "            test_accuracy += accuracy_fn(output,target).item()\n",
    "            del data\n",
    "            del target\n",
    "\n",
    "    test_loss /= len(test_dataloader.dataset)\n",
    "    test_accuracy /= len(test_dataloader.dataset)\n",
    "    return test_loss, test_accuracy\n",
    "    \n",
    "\n",
    "def train_model(model, loss_fn, accuracy_fn, optimizer, train_dataloader, test_dataloader, num_epochs, device, verbose=True, eval_loss_fn=None, print_epoch_summary_interval=10, print_first_epoch=True,lr_scheduler=None, lr_step=2):\n",
    "    training_loss_histogram = []\n",
    "    training_accuracy_histogram = []\n",
    "    testing_loss_histogram = []\n",
    "    testing_accuracy_histogram = []\n",
    "    best_state = model.state_dict()\n",
    "    best_accuracy = 0\n",
    "    model_checkpoint_path =checkpoint_location+\"checkpoint.pt\"\n",
    "    if eval_loss_fn == None:\n",
    "        eval_loss_fn = loss_fn\n",
    "    for epoch in range(num_epochs):\n",
    "        if (((1+epoch)%print_epoch_summary_interval==0) or (epoch==0 and print_first_epoch)) and verbose: \n",
    "            print(\"starting epoch \", (epoch+1))\n",
    "        train_loss, train_accuracy = train_step(model, loss_fn, accuracy_fn, optimizer, train_dataloader, device, eval_loss_fn=eval_loss_fn)\n",
    "        \n",
    "        \n",
    "        if (((1+epoch)%print_epoch_summary_interval==0) or (epoch==0 and print_first_epoch)) and verbose: \n",
    "            print(\"evaluating for epoch\")\n",
    "        \n",
    "        \n",
    "        test_loss, test_accuracy = test_step(model, eval_loss_fn, accuracy_fn, test_dataloader, device)\n",
    "        \n",
    "        if (((1+epoch)%print_epoch_summary_interval==0) or (epoch==0 and print_first_epoch)) and verbose: \n",
    "            print(\"training loss: %s, training accuracy: %s | testing loss: %s, testing accuracy: %s\"%(train_loss, train_accuracy, test_loss, test_accuracy))\n",
    "            print(\"-\"*10)\n",
    "        \n",
    "        if test_accuracy >= best_accuracy:\n",
    "            best_accuracy = test_accuracy            \n",
    "            torch.save(model.state_dict(), model_checkpoint_path)\n",
    "        \n",
    "        training_loss_histogram.append(train_loss)\n",
    "        training_accuracy_histogram.append(train_accuracy)\n",
    "        testing_loss_histogram.append(test_loss)\n",
    "        testing_accuracy_histogram.append(test_accuracy)\n",
    "        if lr_scheduler != None and (epoch+1)%lr_step==0:\n",
    "            lr_scheduler.step()    \n",
    "    model.load_state_dict(torch.load(model_checkpoint_path))\n",
    "    os.remove(model_checkpoint_path)\n",
    "    test_loss, test_accuracy = test_step(model, eval_loss_fn, accuracy_fn, test_dataloader, device)\n",
    "        \n",
    "    if (((1+epoch)%print_epoch_summary_interval==0) or (epoch==0 and print_first_epoch)) and verbose: \n",
    "        print(\"training loss: %s, training accuracy: %s | testing loss: %s, testing accuracy: %s\"%(train_loss, train_accuracy, test_loss, test_accuracy))\n",
    "        print(\"-\"*10)\n",
    "    \n",
    "    testing_loss_histogram.append(test_loss)\n",
    "    testing_accuracy_histogram.append(test_accuracy)\n",
    "    return training_loss_histogram, training_accuracy_histogram, testing_loss_histogram, testing_accuracy_histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b77d1a5-3e23-4dd0-b830-af0ed7938f28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T07:14:03.717810Z",
     "iopub.status.busy": "2023-03-28T07:14:03.717810Z",
     "iopub.status.idle": "2023-03-28T07:14:03.732311Z",
     "shell.execute_reply": "2023-03-28T07:14:03.731312Z",
     "shell.execute_reply.started": "2023-03-28T07:14:03.717810Z"
    }
   },
   "outputs": [],
   "source": [
    "# also define an accuracy function just to make things a bit easier for us. \n",
    "def accuracy(output, target):\n",
    "    pred = output.argmax(dim=1, keepdim=True)\n",
    "    correct = pred.eq(target.view_as(pred)).sum()\n",
    "    return correct\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5196c9de-5e83-4bcf-acec-bc5c1f92caee",
   "metadata": {},
   "source": [
    "## Reproducability\n",
    "It's at this point we need to take some steps to ensure reproducability. We want to get the same results every time we run this notebook, that way we can validate if any changes we make actually result in a change the the results, or if we just got lucky with a particularly good training session. To that end we need to make sure and seed every possible random number source that our model can draw from. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee06b26c-853d-4926-b7a1-84cd46628e25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T07:14:03.733812Z",
     "iopub.status.busy": "2023-03-28T07:14:03.733312Z",
     "iopub.status.idle": "2023-03-28T07:14:03.747312Z",
     "shell.execute_reply": "2023-03-28T07:14:03.746812Z",
     "shell.execute_reply.started": "2023-03-28T07:14:03.733812Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(random_seed)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "random.seed(random_seed)\n",
    "\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5776cc8b-4a47-48d6-9f58-ad39ac6906ce",
   "metadata": {},
   "source": [
    "## Train our models\n",
    "Now for what we've been waiting for, time to train our models. Pretty straight forward loop, for each model we define a new train/test split of the data and pass everything to our training function above, after training we save the model for future use, we'll also keep track of each model's final accuracy based on it's validation set and save a json file with that information. Just in case our run is interupted we can pick up where we left off, or end it early if we so choose, although this will affect the final accuracy. \n",
    "\n",
    "our loop will also print out some stats to help us guage how well each model did after training as well as how long it took."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c42e2100-bcc8-4430-983a-9f523c941790",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T07:14:03.748810Z",
     "iopub.status.busy": "2023-03-28T07:14:03.748312Z",
     "iopub.status.idle": "2023-03-28T15:41:11.290230Z",
     "shell.execute_reply": "2023-03-28T15:41:11.289231Z",
     "shell.execute_reply.started": "2023-03-28T07:14:03.748810Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model  0\n",
      "model id Model_0 training iteration 0 accuracy: 0.9957142857142857 | max accuracy: 0.996904761904762 | training time: 1105.7238903045654 elapsed time: 1106.6318905353546\n",
      "----------\n",
      "training model  1\n",
      "model id Model_1 training iteration 1 accuracy: 0.9952380952380953 | max accuracy: 0.9954761904761905 | training time: 1080.475299358368 elapsed time: 2188.462182044983\n",
      "----------\n",
      "training model  2\n",
      "model id Model_2 training iteration 2 accuracy: 0.9942857142857143 | max accuracy: 0.9966666666666667 | training time: 1042.3256151676178 elapsed time: 3232.1672914028168\n",
      "----------\n",
      "training model  3\n",
      "model id Model_3 training iteration 3 accuracy: 0.9942857142857143 | max accuracy: 0.9957142857142857 | training time: 1041.7905015945435 elapsed time: 4275.349795103073\n",
      "----------\n",
      "training model  4\n",
      "model id Model_4 training iteration 4 accuracy: 0.995 | max accuracy: 0.9973809523809524 | training time: 1036.567997455597 elapsed time: 5313.277292251587\n",
      "----------\n",
      "training model  5\n",
      "model id Model_5 training iteration 5 accuracy: 0.9945238095238095 | max accuracy: 0.996904761904762 | training time: 1020.2714974880219 elapsed time: 6334.838791131973\n",
      "----------\n",
      "training model  6\n",
      "model id Model_6 training iteration 6 accuracy: 0.9966666666666667 | max accuracy: 0.9966666666666667 | training time: 997.591450214386 elapsed time: 7333.693333387375\n",
      "----------\n",
      "training model  7\n",
      "model id Model_7 training iteration 7 accuracy: 0.9959523809523809 | max accuracy: 0.9959523809523809 | training time: 993.5691530704498 elapsed time: 8328.506969928741\n",
      "----------\n",
      "training model  8\n",
      "model id Model_8 training iteration 8 accuracy: 0.9940476190476191 | max accuracy: 0.9945238095238095 | training time: 995.9605231285095 elapsed time: 9325.782859802246\n",
      "----------\n",
      "training model  9\n",
      "model id Model_9 training iteration 9 accuracy: 0.9952380952380953 | max accuracy: 0.996904761904762 | training time: 993.7003829479218 elapsed time: 10320.720755815506\n",
      "----------\n",
      "training model  10\n",
      "model id Model_10 training iteration 10 accuracy: 0.9961904761904762 | max accuracy: 0.9961904761904762 | training time: 992.928416967392 elapsed time: 11314.960150718689\n",
      "----------\n",
      "training model  11\n",
      "model id Model_11 training iteration 11 accuracy: 0.9945238095238095 | max accuracy: 0.996904761904762 | training time: 991.415228843689 elapsed time: 12307.624849319458\n",
      "----------\n",
      "training model  12\n",
      "model id Model_12 training iteration 12 accuracy: 0.9945238095238095 | max accuracy: 0.9966666666666667 | training time: 998.388706445694 elapsed time: 13307.318554639816\n",
      "----------\n",
      "training model  13\n",
      "model id Model_13 training iteration 13 accuracy: 0.9954761904761905 | max accuracy: 0.9954761904761905 | training time: 999.5284280776978 elapsed time: 14308.089516878128\n",
      "----------\n",
      "training model  14\n",
      "model id Model_14 training iteration 14 accuracy: 0.9938095238095238 | max accuracy: 0.9966666666666667 | training time: 995.7344727516174 elapsed time: 15305.06958413124\n",
      "----------\n",
      "training model  15\n",
      "model id Model_15 training iteration 15 accuracy: 0.9952380952380953 | max accuracy: 0.9973809523809524 | training time: 994.4612307548523 elapsed time: 16300.883301019669\n",
      "----------\n",
      "training model  16\n",
      "model id Model_16 training iteration 16 accuracy: 0.9952380952380953 | max accuracy: 0.9954761904761905 | training time: 993.4928319454193 elapsed time: 17295.687794923782\n",
      "----------\n",
      "training model  17\n",
      "model id Model_17 training iteration 17 accuracy: 0.9945238095238095 | max accuracy: 0.9959523809523809 | training time: 990.6034486293793 elapsed time: 18287.6062438488\n",
      "----------\n",
      "training model  18\n",
      "model id Model_18 training iteration 18 accuracy: 0.9947619047619047 | max accuracy: 0.9952380952380953 | training time: 994.7864491939545 elapsed time: 19283.627220392227\n",
      "----------\n",
      "training model  19\n",
      "model id Model_19 training iteration 19 accuracy: 0.991904761904762 | max accuracy: 0.9940476190476191 | training time: 996.467470407486 elapsed time: 20281.401074171066\n",
      "----------\n",
      "training model  20\n",
      "model id Model_20 training iteration 20 accuracy: 0.995 | max accuracy: 0.9959523809523809 | training time: 1007.9043297767639 elapsed time: 21290.569564580917\n",
      "----------\n",
      "training model  21\n",
      "model id Model_21 training iteration 21 accuracy: 0.9947619047619047 | max accuracy: 0.9964285714285714 | training time: 998.8170676231384 elapsed time: 22290.69362783432\n",
      "----------\n",
      "training model  22\n",
      "model id Model_22 training iteration 22 accuracy: 0.9945238095238095 | max accuracy: 0.9971428571428571 | training time: 999.0192062854767 elapsed time: 23291.09333205223\n",
      "----------\n",
      "training model  23\n",
      "model id Model_23 training iteration 23 accuracy: 0.9957142857142857 | max accuracy: 0.9959523809523809 | training time: 996.2053592205048 elapsed time: 24288.620277643204\n",
      "----------\n",
      "training model  24\n",
      "model id Model_24 training iteration 24 accuracy: 0.9959523809523809 | max accuracy: 0.9966666666666667 | training time: 1026.9126362800598 elapsed time: 25316.790636062622\n",
      "----------\n",
      "training model  25\n",
      "model id Model_25 training iteration 25 accuracy: 0.9930952380952381 | max accuracy: 0.995 | training time: 1034.3331151008606 elapsed time: 26352.49425816536\n",
      "----------\n",
      "training model  26\n",
      "model id Model_26 training iteration 26 accuracy: 0.9945238095238095 | max accuracy: 0.9954761904761905 | training time: 1016.330159664154 elapsed time: 27370.097253084183\n",
      "----------\n",
      "training model  27\n",
      "model id Model_27 training iteration 27 accuracy: 0.9940476190476191 | max accuracy: 0.9961904761904762 | training time: 1011.1429364681244 elapsed time: 28382.596150159836\n",
      "----------\n",
      "training model  28\n",
      "model id Model_28 training iteration 28 accuracy: 0.9947619047619047 | max accuracy: 0.9964285714285714 | training time: 1001.0719108581543 elapsed time: 29384.999712228775\n",
      "----------\n",
      "training model  29\n",
      "model id Model_29 training iteration 29 accuracy: 0.995 | max accuracy: 0.9966666666666667 | training time: 1038.3635354042053 elapsed time: 30424.6882045269\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model_scores = {}\n",
    "training_start_time = time.time()\n",
    "for i in range(num_models_to_train):\n",
    "    train_dataloader, val_dataloader = create_train_val_dataloaders(train_features, train_labels, train_transformer=train_transform, test_size=.1)\n",
    "    print(\"training model \", i)\n",
    "    model_id = \"Model_\"+str(i)\n",
    "    model_path =checkpoint_location+model_id+\".pt\"\n",
    "    model = Model().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
    "    loss_fn = F.cross_entropy\n",
    "    \n",
    "    train_start = time.time()\n",
    "    training_loss_hist, training_accuracy_histogram, testing_loss_hist, testing_accuracy_histogram = train_model(model, loss_fn, accuracy, optimizer, train_dataloader, val_dataloader, num_epochs, device, verbose=False, lr_scheduler=lr_scheduler, print_epoch_summary_interval=5)\n",
    "    test_accuracy = testing_accuracy_histogram[-2]\n",
    "    max_accuracy = max(testing_accuracy_histogram) # this max accuracy is the final accuracy of our model, since the training function loads back in the best performing model before returning. \n",
    "    training_time = time.time() - train_start\n",
    "    elapsed_time = time.time() - training_start_time\n",
    "    print(\"model id %s training iteration %s accuracy: %s | max accuracy: %s | training time: %s elapsed time: %s\"%(model_id, i, test_accuracy, max_accuracy, training_time, elapsed_time))\n",
    "    \n",
    "   \n",
    "    model_scores[model_id] =  {\n",
    "        \"file_path\":model_path,\n",
    "        \"score\": max_accuracy\n",
    "    }\n",
    "    cpu_model = model.cpu()\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    del model\n",
    "    with open(scores_json_location, \"w\") as outfile:\n",
    "        json.dump(model_scores, outfile)\n",
    "    print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adff3ff-23df-4ce5-aad2-de246c7d7f7d",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "At this point our models and our model json have been saved to disk, so if something were to happen, say you have to stop the notebook and restart, you could pick up from here rather than having to rerun the entire training segment again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3cc21629-af68-431c-9b62-53be590f09a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T15:41:11.291730Z",
     "iopub.status.busy": "2023-03-28T15:41:11.291730Z",
     "iopub.status.idle": "2023-03-28T15:41:11.305766Z",
     "shell.execute_reply": "2023-03-28T15:41:11.304729Z",
     "shell.execute_reply.started": "2023-03-28T15:41:11.291730Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file_path': './model_checkpoints/Model_0.pt', 'score': 0.996904761904762},\n",
       " {'file_path': './model_checkpoints/Model_1.pt', 'score': 0.9954761904761905},\n",
       " {'file_path': './model_checkpoints/Model_2.pt', 'score': 0.9966666666666667},\n",
       " {'file_path': './model_checkpoints/Model_3.pt', 'score': 0.9957142857142857},\n",
       " {'file_path': './model_checkpoints/Model_4.pt', 'score': 0.9973809523809524},\n",
       " {'file_path': './model_checkpoints/Model_5.pt', 'score': 0.996904761904762},\n",
       " {'file_path': './model_checkpoints/Model_6.pt', 'score': 0.9966666666666667},\n",
       " {'file_path': './model_checkpoints/Model_7.pt', 'score': 0.9959523809523809},\n",
       " {'file_path': './model_checkpoints/Model_8.pt', 'score': 0.9945238095238095},\n",
       " {'file_path': './model_checkpoints/Model_9.pt', 'score': 0.996904761904762},\n",
       " {'file_path': './model_checkpoints/Model_10.pt', 'score': 0.9961904761904762},\n",
       " {'file_path': './model_checkpoints/Model_11.pt', 'score': 0.996904761904762},\n",
       " {'file_path': './model_checkpoints/Model_12.pt', 'score': 0.9966666666666667},\n",
       " {'file_path': './model_checkpoints/Model_13.pt', 'score': 0.9954761904761905},\n",
       " {'file_path': './model_checkpoints/Model_14.pt', 'score': 0.9966666666666667},\n",
       " {'file_path': './model_checkpoints/Model_15.pt', 'score': 0.9973809523809524},\n",
       " {'file_path': './model_checkpoints/Model_16.pt', 'score': 0.9954761904761905},\n",
       " {'file_path': './model_checkpoints/Model_17.pt', 'score': 0.9959523809523809},\n",
       " {'file_path': './model_checkpoints/Model_18.pt', 'score': 0.9952380952380953},\n",
       " {'file_path': './model_checkpoints/Model_19.pt', 'score': 0.9940476190476191},\n",
       " {'file_path': './model_checkpoints/Model_20.pt', 'score': 0.9959523809523809},\n",
       " {'file_path': './model_checkpoints/Model_21.pt', 'score': 0.9964285714285714},\n",
       " {'file_path': './model_checkpoints/Model_22.pt', 'score': 0.9971428571428571},\n",
       " {'file_path': './model_checkpoints/Model_23.pt', 'score': 0.9959523809523809},\n",
       " {'file_path': './model_checkpoints/Model_24.pt', 'score': 0.9966666666666667},\n",
       " {'file_path': './model_checkpoints/Model_25.pt', 'score': 0.995},\n",
       " {'file_path': './model_checkpoints/Model_26.pt', 'score': 0.9954761904761905},\n",
       " {'file_path': './model_checkpoints/Model_27.pt', 'score': 0.9961904761904762},\n",
       " {'file_path': './model_checkpoints/Model_28.pt', 'score': 0.9964285714285714},\n",
       " {'file_path': './model_checkpoints/Model_29.pt', 'score': 0.9966666666666667}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load back in our model scores data\n",
    "model_scores_values = list(model_scores.values())\n",
    "model_scores_values # verify the contents....just in case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c519312-4314-4258-b002-ea3b470647ca",
   "metadata": {},
   "source": [
    "now we load back in our models for another round of evaluation, now we want to score each model based on how well it does against the entire training data and sort them based on those scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4494efbf-667f-4ff8-91b8-cb8eacafd464",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T15:41:11.306730Z",
     "iopub.status.busy": "2023-03-28T15:41:11.306230Z",
     "iopub.status.idle": "2023-03-28T15:41:16.280730Z",
     "shell.execute_reply": "2023-03-28T15:41:16.279728Z",
     "shell.execute_reply.started": "2023-03-28T15:41:11.306730Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "for model_details in model_scores_values:\n",
    "    file_path = model_details['file_path']\n",
    "    model = Model()\n",
    "    model.load_state_dict(torch.load(file_path))\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ddc925-826d-4c7b-b5d3-27ad41a57874",
   "metadata": {},
   "source": [
    "## Final Model Selection\n",
    "now we need to find the top 10 models we want to ensemble. We'll do this by scoring each model on the entire dataset and selecting the best overall performers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21ba73e1-27f5-4446-ac78-297c7ad443bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T15:41:16.282230Z",
     "iopub.status.busy": "2023-03-28T15:41:16.281730Z",
     "iopub.status.idle": "2023-03-28T15:44:13.345731Z",
     "shell.execute_reply": "2023-03-28T15:44:13.344230Z",
     "shell.execute_reply.started": "2023-03-28T15:41:16.282230Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9980952380952381\n",
      "1 0.9972380952380953\n",
      "2 0.9980238095238095\n",
      "3 0.9978809523809524\n",
      "4 0.9980714285714286\n",
      "5 0.9976666666666667\n",
      "6 0.9980238095238095\n",
      "7 0.9981428571428571\n",
      "8 0.9980476190476191\n",
      "9 0.9980476190476191\n",
      "10 0.9982142857142857\n",
      "11 0.9978809523809524\n",
      "12 0.9979523809523809\n",
      "13 0.9982380952380953\n",
      "14 0.996904761904762\n",
      "15 0.9978333333333333\n",
      "16 0.9983333333333333\n",
      "17 0.9965714285714286\n",
      "18 0.997452380952381\n",
      "19 0.997547619047619\n",
      "20 0.9976428571428572\n",
      "21 0.9976190476190476\n",
      "22 0.9977857142857143\n",
      "23 0.9970476190476191\n",
      "24 0.9982142857142857\n",
      "25 0.998\n",
      "26 0.9979047619047619\n",
      "27 0.9979761904761905\n",
      "28 0.9982619047619048\n",
      "29 0.9975714285714286\n"
     ]
    }
   ],
   "source": [
    "# very similar to the loop we had before, this time we just pass in a single dataloader to our test_step function to get an overall accuracy. \n",
    "train_dataloader = create_dataloader(train_features, train_labels, ToTensor(), g)\n",
    "best_accuracy = 0 \n",
    "best_n = 1\n",
    "scores = []\n",
    "for i, model in enumerate(models):\n",
    "    device_model = model.to(device)\n",
    "    loss_eval_fn = lambda output, target: F.nll_loss(output,target, reduction='sum')\n",
    "\n",
    "    test_loss, test_accuracy = test_step(device_model, loss_eval_fn, accuracy, train_dataloader, device)\n",
    "    del device_model\n",
    "    print(i, test_accuracy)\n",
    "    scores.append((test_accuracy, model, i))\n",
    "    if test_accuracy > best_accuracy:\n",
    "        best_accuracy = test_accuracy\n",
    "        best_n = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cfea6a4-e661-4aa1-b474-d95f78d7f7e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T15:44:13.347230Z",
     "iopub.status.busy": "2023-03-28T15:44:13.346731Z",
     "iopub.status.idle": "2023-03-28T15:44:13.360729Z",
     "shell.execute_reply": "2023-03-28T15:44:13.359730Z",
     "shell.execute_reply.started": "2023-03-28T15:44:13.347230Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now that we have the model scores on the entire training dataset, sort the models based on performance\n",
    "scores.sort(key=lambda x: x[0], reverse=True)\n",
    "scored_models = [x[1] for x in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7fc89c4c-d25c-466f-9791-74b38b03f891",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T06:52:52.249442Z",
     "iopub.status.busy": "2023-03-29T06:52:52.248943Z",
     "iopub.status.idle": "2023-03-29T06:52:52.256444Z",
     "shell.execute_reply": "2023-03-29T06:52:52.255447Z",
     "shell.execute_reply.started": "2023-03-29T06:52:52.249442Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# and select the top 10 models\n",
    "selected_models = scored_models[:num_models_to_ensemble]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8894ed80-55bb-4e86-b1bb-2a2550197276",
   "metadata": {},
   "source": [
    "## Ensembling\n",
    "Now to take those selected models and ensemble them together to make our final predictions. The actual process is pretty straightforward, pass the data through each model and sum their predictions together and softmax the results to get a final prediction. To make it a bit easier we'll go ahead and use a class to help load and unload each model from the gpu (if present)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e184695-6a45-4768-bd43-cace043930ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T15:44:13.378231Z",
     "iopub.status.busy": "2023-03-28T15:44:13.377731Z",
     "iopub.status.idle": "2023-03-28T15:44:13.391731Z",
     "shell.execute_reply": "2023-03-28T15:44:13.390731Z",
     "shell.execute_reply.started": "2023-03-28T15:44:13.378231Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EnsembleModel():\n",
    "    def __init__(self, sub_models):\n",
    "        self.models = sub_models \n",
    "        self.device = \"cpu\"\n",
    "        \n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        for model in self.models:\n",
    "            device_model = model.to(self.device)\n",
    "            device_model.eval()\n",
    "            output = device_model.get_logits(x).detach()\n",
    "            outputs.append(output)\n",
    "            del device_model\n",
    "        output = sum(outputs)\n",
    "        output = F.log_softmax(output, dim=1)\n",
    "        return output\n",
    "    def to(self, device):\n",
    "        self.device = device\n",
    "        return self\n",
    "    def eval(self):\n",
    "        for model in self.models:\n",
    "            model.eval()\n",
    "        \n",
    "            \n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa4175f2-28ae-4fa1-84b6-7e0664a19dc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T15:44:13.393730Z",
     "iopub.status.busy": "2023-03-28T15:44:13.393231Z",
     "iopub.status.idle": "2023-03-28T15:44:14.756231Z",
     "shell.execute_reply": "2023-03-28T15:44:14.754891Z",
     "shell.execute_reply.started": "2023-03-28T15:44:13.393730Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load our test data for the kaggle hold out\n",
    "holdout_data_df = pd.read_csv(input_folder_path+\"test.csv\")\n",
    "holdout_images = (holdout_data_df.iloc[:,:].values).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28a9a215-27ed-425a-9e34-e4063e67f4ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T15:44:14.757762Z",
     "iopub.status.busy": "2023-03-28T15:44:14.757230Z",
     "iopub.status.idle": "2023-03-28T15:44:14.771231Z",
     "shell.execute_reply": "2023-03-28T15:44:14.770230Z",
     "shell.execute_reply.started": "2023-03-28T15:44:14.757762Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(holdout_data_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad78e8c0-24ca-4aa8-9dff-5f437233db91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T15:44:14.772232Z",
     "iopub.status.busy": "2023-03-28T15:44:14.772232Z",
     "iopub.status.idle": "2023-03-28T15:44:31.867230Z",
     "shell.execute_reply": "2023-03-28T15:44:31.866229Z",
     "shell.execute_reply.started": "2023-03-28T15:44:14.772232Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "holdout_tensor = torch.tensor(holdout_images)\n",
    "holdout_dataset = CustomTensorDataset(holdout_tensor, None, transform=ToTensor())\n",
    "holdout_dataloader = DataLoader(holdout_dataset, batch_size=batch_size, generator=g)\n",
    "\n",
    "ensemble_model = EnsembleModel(selected_models)\n",
    "ensemble_model.to(device)\n",
    "loss_fn = F.cross_entropy\n",
    "\n",
    "predictions = [] \n",
    "for features in holdout_dataloader:\n",
    "    features = features.to(device)\n",
    "    new_predictions = ensemble_model(features)\n",
    "    new_predictions = new_predictions.cpu().detach().numpy()\n",
    "    results = np.argmax(new_predictions, axis = 1)\n",
    "    predictions.extend(list(results))\n",
    "    del features\n",
    "    del new_predictions\n",
    "df = pd.DataFrame(predictions, columns=['Label'])\n",
    "submission = pd.concat([pd.Series(range(1,28001), name = \"ImageId\"), df],axis = 1)\n",
    "submission.to_csv(\"MNIST-ENSEMBLE-SUBMISSION.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd18daea-daac-4685-81fa-b376320bc70c",
   "metadata": {},
   "source": [
    "## Final Results and Data Musings, a final score of 99.68% accuracy!\n",
    "The final submission should earn a score of 99.68%, a respectable score but could be much higher. A major issues with getting a higher score is the data for the Kaggle MNIST dataset compared to toehr MNIST sources. The MNIST dataset has 70k labeled images, the default split is 60k for training and a 10k holdout dataset for validation. This is how sources like PyTorch and Tensorflow seperate the data, kaggle on the other hand has only 42k images for training and 28k for the holdout/validation. If you properly split the data into a train/test set from the training images to prevent overfitting then that means that for kaggle you train on even less. In this notebook we did a 90/10 split for training/test so we trained on 37.8k images, whereas with pytorch we would have trained with 54k. This is a signifigant gap between the sample sizes. That means for the same number of epochs a model trained on the Pytorch split would have seen almost double the amount of images as the kaggle split, that means there was a higher variation of images seen which means the model had a better chance toe generalize and learn the patterns as opposed to the kaggle version. \n",
    "\n",
    "Simply put, with a similar model architecture and data augmentation strategy I was able to repeatedly reach a 99.7% accuracy (sometimes as high as 99.75% on a good training run) using the PyTorch split of the data within only 20 training epochs per model, where I struggled to achieve anything higher than 99.5% with the kaggle split with the same number of epochs. \n",
    "\n",
    "A more aggressive Data Augmentation strategy helps to bridge this gap, as well as training for more epochs. But overall I was getting diminishing returns with this approach. Even reference notebooks I found on Kaggle struggled to achieve their advertised accuracy, and instead their results seemed more of an occurance of a good training run rather than deliberate strategy (at least it appeared that way). There is no denying that luck plays a part in the final result of the model, how the weights are initialized and how the data is augmented through the random transforms, but I am not unconvinced that there might be a better strategy or approach to effectively reach the 99.75% accuracy I was aiming for originally. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b18a2d6-9653-4e55-90f9-adaca529e7f8",
   "metadata": {},
   "source": [
    "## Lessons Learned\n",
    "- Luck plays more of a role in Deep Learning that I originally thought. I always knew that it played a factor but this excersize really highlighted the variance that a model can have.\n",
    "- Because luck plays such a factor, experiment reproducability is a neccissity for any future projects. I need to be able to determine if an adjustment to the architecture or training strategy resulted in a chance in accuracy or if it was just the luck of the draw.\n",
    "- Just because the top n models perform well doesn't mean they will produce the best ensemble model from the pool of available models (More on this later in the notebook)\n",
    "- I am extremely long winded and this notebook is way too long "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba846264-1c45-4b46-b063-f510a522a7af",
   "metadata": {},
   "source": [
    "## Possible Improvements\n",
    "- I think that perhaps a more deliberate selection of models based on their performance would be beneficial for ensembling. For example if the top model struggles with a particular class pairing it with a model that performs well in that class but not detrmintally bad for the rest of the classes available would be more beneficial than pairing it with a random model. This way the models work off each other to cover their weaknesses. In this notebook I blindly picked the top 10 models with no other analysis done on their compatability. \n",
    "- Perhaps a more deliberate training on the models for a specific class would also help. So rather than training n general models that try to predict every class well, train models to classify a specific class extremely well and does moderatly well on others. A sort of T shaped approach where it does reasonably well on all classes but outperforms on a specific class.\n",
    "- The ensemble method used here is also pretty basic, simply summing the outputs from the individual models, a more advanced models that take the original image as input and the ensemble models predictions as input into a neural network of it's own might produce better results. The new model might be able to pick out instances of when to listen to a particular model over listening to the others based on patterns that exist in the data. \n",
    "- Data Augmentation, I still think the data augmentation I used here could be more robust/aggressive, generating more varied samples to help extend the limited dataset might have helped enhance the final score. \n",
    "- Better parallelization, pytorch dataloaders can benefit from having multiple workers to process data and prepare the next batch, however I had issues when trying to enable this on my system and the workers would crash. Need to investigate this to gain performance boost. \n",
    "- Writting more concise notebooks on project results!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dad336-77de-4552-83e3-fa6c5cd029ef",
   "metadata": {},
   "source": [
    "## Extra: Going beyond the 99.68% with the models from this notebook\n",
    "As an experiment I decided to randomly select models from the pool of models produced by this notebook, overall I tried countless combinations of the models in this notebook to try and find a combination to beat the above score with the top 10 scoring models. What I found is that it is possible to achieve 99.7% accuracy! It is possible that a higher score is possible with a different combination but this is the highest I found.\n",
    "\n",
    "With the models arranged in the order they were trained, it's possible to achieve a higher score with the model indicies [10, 8, 3, 24, 4, 5]. These were not selected by any deliberate process or analysis, so I excluded the code I used to find them (was literally just picking them at random), however I did want to show that it was possible to achieve a higher score with the models trained on this notebook with ensembling. The cells below will make an alternate submission csv using these models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db9d21af-394e-4773-a3f9-6c973073a866",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T15:47:18.359444Z",
     "iopub.status.busy": "2023-03-28T15:47:18.359444Z",
     "iopub.status.idle": "2023-03-28T15:47:29.517945Z",
     "shell.execute_reply": "2023-03-28T15:47:29.517444Z",
     "shell.execute_reply.started": "2023-03-28T15:47:18.359444Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ideal_model_indicies = [10, 8, 3, 24, 4, 5]\n",
    "selected_models = [models[i] for i in ideal_model_indicies]\n",
    "\n",
    "ensemble_model = EnsembleModel(selected_models)\n",
    "ensemble_model.to(device)\n",
    "loss_fn = F.cross_entropy\n",
    "\n",
    "predictions = [] \n",
    "for features in holdout_dataloader:\n",
    "    features = features.to(device)\n",
    "    new_predictions = ensemble_model(features)\n",
    "    new_predictions = new_predictions.cpu().detach().numpy()\n",
    "    results = np.argmax(new_predictions, axis = 1)\n",
    "    predictions.extend(list(results))\n",
    "    del features\n",
    "    del new_predictions\n",
    "df = pd.DataFrame(predictions, columns=['Label'])\n",
    "submission = pd.concat([pd.Series(range(1,28001), name = \"ImageId\"), df],axis = 1)\n",
    "submission.to_csv(\"MNIST-ENSEMBLE-SUBMISSION-99.7.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccd1d15-5070-480a-8e06-adf326b4cc69",
   "metadata": {},
   "source": [
    "## References and Special Thanks\n",
    "Before I forget I wanted to point out a few notebooks that I ended up referencing quite a bit for this project. \n",
    "\n",
    "* [How to score 97%, 98%, 99%, and 100% by Chris Deotte](https://www.kaggle.com/c/digit-recognizer/discussion/61480) - a really good breakdown of how to achieve different levels of results for the dataset and links to several notebooks for reference. \n",
    "* [25 Million Images! [0.99757] MNIST by Chris Deotte](https://www.kaggle.com/code/cdeotte/25-million-images-0-99757-mnist/notebook) - a really good example of ensembling in tensorflow for this dataset. I had some issues replicating some of his results, the highest run I achieved for this ntoebook was 99.67, but still an awesome reference.\n",
    "* [MNIST Perfect 100% using kNN by Chris Deotte](https://www.kaggle.com/code/cdeotte/mnist-perfect-100-using-knn/notebook) - This was an interesting read, it does \"cheat\" to achieve the 100% accuracy, but still a useful resource. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ea58ab-79aa-416c-a8ed-901ed2923a01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0261a295-c18d-4803-af1b-037ffe01818a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58586c79-aa56-4a56-b9b9-6a7ca6fb0a49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255f5a24-4cbd-4a5e-9b09-4fae875a6842",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
